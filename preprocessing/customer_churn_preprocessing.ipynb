{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36b3458a-4351-4847-a523-aaf452dee0ba",
   "metadata": {},
   "source": [
    "# Customer Churn Prediction\n",
    "## **Question?** Will they churn once their current set of policies expire?\n",
    "### **Churned**: no policy for (>=6 months)\n",
    "### **Non-Churned**: has policy for (2 years+) and not without policy for (>=6 months) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041568ad-ad93-4aea-8a1e-e785d25dc33b",
   "metadata": {},
   "source": [
    "## **Features**:\n",
    "1. First policy year (static)\n",
    "2. Sum of premiums in USD (dynamic)\n",
    "3. Sum of claims in USD (dynamic)\n",
    "4. Number of policies (dynamic)\n",
    "5. Number of claims (dynamic)\n",
    "6. State (mode; static)\n",
    "7. County (mode; static)\n",
    "8. Sum of deductibles (dynamic)\n",
    "9. Average equipment year (dynamic)\n",
    "10. Average location premium (dynamic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24739974-760b-4089-a807-46edd825411a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35878016-845c-4a4f-8ae5-5b86558d3f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generic Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c3591d0-9048-4cd8-9797-86d923b5a7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "claims_data = '../data/claims.csv'\n",
    "premiums_data = '../data/premiums.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52321453-ed17-4141-baa4-4497223aae99",
   "metadata": {},
   "outputs": [],
   "source": [
    "claims_df = pd.read_csv(claims_data)\n",
    "premiums_df = pd.read_csv(premiums_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f370dac-9082-4dd1-a290-37109e89e0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "claims_df = claims_df[~claims_df['ClaimCause'].isin(['Claim Denied', 'Claim Withdrawn'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54522fc9-cb8d-41ba-a409-7c0f81011fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "claims_df = claims_df.dropna()\n",
    "\n",
    "claims_df['DateOfLoss'] = pd.to_datetime(claims_df['DateOfLoss'])\n",
    "claims_df['ClaimReceivedDate'] = pd.to_datetime(claims_df['ClaimReceivedDate'])\n",
    "claims_df['PolicyEffectiveDate'] = pd.to_datetime(claims_df['PolicyEffectiveDate'])\n",
    "\n",
    "claims_df = claims_df.astype({\n",
    "    'PolicyNumber': 'string',\n",
    "    'ClaimCause': 'string',\n",
    "    'County': 'string',\n",
    "    'State': 'string'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e310a29e-1fc4-4546-8dc4-e657f2aef8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "premiums_df = premiums_df.dropna()\n",
    "\n",
    "premiums_df['PolicyEffectiveDate'] = pd.to_datetime(premiums_df['PolicyEffectiveDate'])\n",
    "premiums_df['PolicyExpirationDate'] = pd.to_datetime(premiums_df['PolicyExpirationDate'])\n",
    "\n",
    "premiums_df = premiums_df.astype({\n",
    "    'PolicyNumber': 'string',\n",
    "    'County': 'string',\n",
    "    'State': 'string'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "112e33c9-d2b6-414f-aba6-b106bb6282a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "premiums_df = premiums_df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "703010c4-58c1-4753-bedf-103d8df371d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def impute_zero_for_year(\n",
    "    value : float\n",
    ") -> float:\n",
    "    current_year = datetime.now().year\n",
    "    if 1950.0 <= value <= current_year:\n",
    "        return value\n",
    "    else:\n",
    "        return np.NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc5e6eff-132f-42c7-9fc4-a64833edc4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "premiums_df['Equip Year'] = premiums_df['Equip Year'].apply(impute_zero_for_year)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a62a9a59-797a-4d92-a395-00de63c73bbc",
   "metadata": {},
   "source": [
    "## The below logic is only for getting positive samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bbce9d7a-9dbe-427f-bc2e-948b63dbb2fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished 100 additional iterations.\n",
      "Finished 100 additional iterations.\n",
      "Finished 100 additional iterations.\n",
      "Finished 100 additional iterations.\n",
      "Finished 100 additional iterations.\n",
      "Finished 100 additional iterations.\n",
      "Finished 100 additional iterations.\n",
      "Finished 100 additional iterations.\n",
      "Finished 100 additional iterations.\n",
      "Finished 100 additional iterations.\n",
      "Finished 100 additional iterations.\n",
      "Finished 100 additional iterations.\n",
      "Finished 100 additional iterations.\n",
      "Finished 100 additional iterations.\n",
      "Finished 100 additional iterations.\n",
      "Finished 100 additional iterations.\n",
      "Finished 100 additional iterations.\n",
      "Finished 100 additional iterations.\n",
      "Finished 100 additional iterations.\n",
      "Finished 100 additional iterations.\n",
      "Finished 100 additional iterations.\n",
      "Finished 100 additional iterations.\n",
      "Finished 100 additional iterations.\n",
      "Finished 100 additional iterations.\n",
      "Finished 100 additional iterations.\n",
      "Finished 100 additional iterations.\n"
     ]
    }
   ],
   "source": [
    "all_positive_customer_data = pd.DataFrame([], columns = [\n",
    "    'min_policy_date', 'sum_policy_premiums',\n",
    "    'sum_location_premiums', 'no_previous_equipment',\n",
    "    'state', 'sum_of_deductibles',\n",
    "    'avg_equipment_year', 'total_claim_amount', 'churned'\n",
    "])\n",
    "\n",
    "unique_customer_ids = premiums_df['CustomerId'].unique()\n",
    "positive_sample_customer_ids = []\n",
    "\n",
    "iteration = 0\n",
    "for customer_id in unique_customer_ids:\n",
    "    date_list = []\n",
    "    for index, row in premiums_df.loc[premiums_df['CustomerId'] == customer_id].iterrows():\n",
    "        start_date = str(row['PolicyEffectiveDate'].date())\n",
    "        end_date = str(row['PolicyExpirationDate'].date())\n",
    "    \n",
    "        date_range = pd.date_range(start_date, end_date).values.astype('datetime64[D]')\n",
    "        date_strings = np.datetime_as_string(date_range, unit = 'D').tolist()\n",
    "        \n",
    "        date_list += date_strings\n",
    "    \n",
    "    unique_active_dates = np.unique(date_list)\n",
    "    \n",
    "    customer_date_range = pd.DataFrame({\n",
    "        'ProbeDate': pd.date_range(\n",
    "            premiums_df['PolicyEffectiveDate'].min(),\n",
    "            premiums_df['PolicyExpirationDate'].max(),\n",
    "            freq = 'D'\n",
    "        )\n",
    "    })\n",
    "    \n",
    "    customer_date_range['CustomerId'] = customer_id\n",
    "    customer_date_range['ActivePolicy'] = 0\n",
    "    customer_date_range.loc[customer_date_range['ProbeDate'].isin(unique_active_dates), 'ActivePolicy'] = 1\n",
    "    \n",
    "    customer_date_range = customer_date_range.loc[customer_date_range['ProbeDate'] < '2023-01-01']\n",
    "    \n",
    "    customer_date_range['ProbePosition'] = 0\n",
    "    \n",
    "    def find_switch(\n",
    "        df : pd.DataFrame,\n",
    "        col : str\n",
    "    ) -> list:\n",
    "        switch_indices = df[df[col].diff() == -1].index\n",
    "        for idx in switch_indices:\n",
    "            if (df.loc[idx : idx + 179, col] == 0).all():\n",
    "                return idx\n",
    "        return None\n",
    "    \n",
    "    index = find_switch(customer_date_range, 'ActivePolicy')\n",
    "\n",
    "    if index != None:\n",
    "        customer_date_range.loc[\n",
    "            [index - 45, index - 90, index - 135, index - 180, index - 225, index - 270, index - 315, index - 360],\n",
    "            'ProbePosition'\n",
    "        ] = 1\n",
    "        positive_sample_customer_ids.append(customer_id)\n",
    "    else:\n",
    "        continue\n",
    "    \n",
    "    customer_probe_dates = customer_date_range \\\n",
    "                        .loc[customer_date_range['ProbePosition'] == 1][['CustomerId', 'ProbeDate']] \\\n",
    "                        .reset_index(drop = True)\n",
    "    \n",
    "    def first(x):\n",
    "        return x.iloc[0]\n",
    "    \n",
    "    def row_count(x):\n",
    "        return len(x)\n",
    "    \n",
    "    all_probe_data = []\n",
    "    for index, row in customer_probe_dates.iterrows():\n",
    "        filtered_premium_df = premiums_df.loc[(premiums_df['CustomerId'] == customer_id) & (premiums_df['PolicyEffectiveDate'] < row['ProbeDate'])]\n",
    "        probe_premium_data = filtered_premium_df.agg({\n",
    "            'PolicyEffectiveDate': 'min',\n",
    "            'PolicyPremium': 'sum',\n",
    "            'LocationPremium': 'sum',\n",
    "            'Loc': 'max',\n",
    "            'State': first,\n",
    "            'Deductible': 'sum',\n",
    "            'Equip Year': 'mean'\n",
    "        }).values\n",
    "    \n",
    "        filtered_claims_df = claims_df.loc[(claims_df['CustomerId'] == customer_id) & (claims_df['PolicyEffectiveDate'] < row['ProbeDate'])]\n",
    "        probe_claims_data = filtered_claims_df.agg({\n",
    "            'TotalPaidToDate': 'sum'\n",
    "        }).values\n",
    "    \n",
    "        probe_data = list(probe_premium_data.astype(str)) + list(probe_claims_data.astype(str)) + ['1']\n",
    "    \n",
    "        all_probe_data.append(probe_data)\n",
    "    \n",
    "    customer_data = pd.DataFrame(all_probe_data, columns = [\n",
    "        'min_policy_date', 'sum_policy_premiums',\n",
    "        'sum_location_premiums', 'no_previous_equipment',\n",
    "        'state', 'sum_of_deductibles',\n",
    "        'avg_equipment_year', 'total_claim_amount', 'churned'\n",
    "    ])\n",
    "    \n",
    "    customer_data = customer_data.drop_duplicates()\n",
    "\n",
    "    all_positive_customer_data = pd.concat([all_positive_customer_data, customer_data], ignore_index = True)\n",
    "\n",
    "    iteration += 1\n",
    "    if iteration % 100 == 0:\n",
    "        print('Finished 100 additional iterations.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ccdcbf4-1427-4216-adb8-6fb9c207d882",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>min_policy_date</th>\n",
       "      <th>sum_policy_premiums</th>\n",
       "      <th>sum_location_premiums</th>\n",
       "      <th>no_previous_equipment</th>\n",
       "      <th>state</th>\n",
       "      <th>sum_of_deductibles</th>\n",
       "      <th>avg_equipment_year</th>\n",
       "      <th>total_claim_amount</th>\n",
       "      <th>churned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-03-01 00:00:00</td>\n",
       "      <td>594</td>\n",
       "      <td>594.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NE</td>\n",
       "      <td>1000</td>\n",
       "      <td>1994.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-08-10 00:00:00</td>\n",
       "      <td>90240</td>\n",
       "      <td>15040.0</td>\n",
       "      <td>6</td>\n",
       "      <td>TX</td>\n",
       "      <td>12000</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>11266.51</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-06-13 00:00:00</td>\n",
       "      <td>6804</td>\n",
       "      <td>6804.0</td>\n",
       "      <td>1</td>\n",
       "      <td>TX</td>\n",
       "      <td>3000</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-03-27 00:00:00</td>\n",
       "      <td>164640</td>\n",
       "      <td>23520.0</td>\n",
       "      <td>7</td>\n",
       "      <td>TX</td>\n",
       "      <td>21000</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-06-15 00:00:00</td>\n",
       "      <td>912</td>\n",
       "      <td>912.0</td>\n",
       "      <td>1</td>\n",
       "      <td>TX</td>\n",
       "      <td>1000</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       min_policy_date sum_policy_premiums sum_location_premiums  \\\n",
       "0  2018-03-01 00:00:00                 594                 594.0   \n",
       "1  2018-08-10 00:00:00               90240               15040.0   \n",
       "2  2018-06-13 00:00:00                6804                6804.0   \n",
       "3  2018-03-27 00:00:00              164640               23520.0   \n",
       "4  2020-06-15 00:00:00                 912                 912.0   \n",
       "\n",
       "  no_previous_equipment state sum_of_deductibles avg_equipment_year  \\\n",
       "0                     1    NE               1000             1994.0   \n",
       "1                     6    TX              12000             2004.0   \n",
       "2                     1    TX               3000             2018.0   \n",
       "3                     7    TX              21000             2003.0   \n",
       "4                     1    TX               1000             2013.0   \n",
       "\n",
       "  total_claim_amount churned  \n",
       "0                0.0       1  \n",
       "1           11266.51       1  \n",
       "2                0.0       1  \n",
       "3                0.0       1  \n",
       "4                0.0       1  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_positive_customer_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a38cc4e8-f8a8-45e9-a826-520c2804d687",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_positive_customer_data.to_csv('../data/churn_modeling/churn_prediction_positive_samples.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0b424c94-a36f-42cd-9a0a-78e8bb0b014f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PolicyNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Loc</th>\n",
       "      <th>PolicyEffectiveDate</th>\n",
       "      <th>PolicyExpirationDate</th>\n",
       "      <th>PolicyPremium</th>\n",
       "      <th>LocationPremium</th>\n",
       "      <th>Deductible</th>\n",
       "      <th>LocValue</th>\n",
       "      <th>County</th>\n",
       "      <th>State</th>\n",
       "      <th>Equip Year</th>\n",
       "      <th>Equip Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>P-376-2019</td>\n",
       "      <td>4241</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-03-07</td>\n",
       "      <td>2020-03-07</td>\n",
       "      <td>67668</td>\n",
       "      <td>1931.057074</td>\n",
       "      <td>2500</td>\n",
       "      <td>150000.0</td>\n",
       "      <td>Union</td>\n",
       "      <td>NM</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>150000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>P-376-2019</td>\n",
       "      <td>4241</td>\n",
       "      <td>2</td>\n",
       "      <td>2019-03-07</td>\n",
       "      <td>2020-03-07</td>\n",
       "      <td>67668</td>\n",
       "      <td>1931.057074</td>\n",
       "      <td>2500</td>\n",
       "      <td>150000.0</td>\n",
       "      <td>Union</td>\n",
       "      <td>NM</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>150000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PolicyNumber  CustomerId  Loc PolicyEffectiveDate PolicyExpirationDate  \\\n",
       "68   P-376-2019        4241    1          2019-03-07           2020-03-07   \n",
       "69   P-376-2019        4241    2          2019-03-07           2020-03-07   \n",
       "\n",
       "    PolicyPremium  LocationPremium  Deductible  LocValue County State  \\\n",
       "68          67668      1931.057074        2500  150000.0  Union    NM   \n",
       "69          67668      1931.057074        2500  150000.0  Union    NM   \n",
       "\n",
       "    Equip Year  Equip Value  \n",
       "68      2006.0     150000.0  \n",
       "69      2006.0     150000.0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "premiums_df.loc[premiums_df['CustomerId'] == 4241].head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1bb6e5-413a-47c0-84dd-9b69aaf08f6d",
   "metadata": {},
   "source": [
    "## The below logic is only for getting negative samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "07ec04fb-3c19-4afb-8ccb-f855d8dee66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_customer_samples = premiums_df.groupby('CustomerId').agg({\n",
    "    'PolicyEffectiveDate': 'min',\n",
    "    'PolicyExpirationDate': 'max'\n",
    "}).reset_index(drop = False).rename(columns = {\n",
    "    'PolicyEffectiveDate': 'minPolicyEffectiveDate',\n",
    "    'PolicyExpirationDate': 'maxPolicyExpirationDate'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eabdbba3-d4b5-4e2f-9af6-a3f76108917b",
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_customer_samples = negative_customer_samples.loc[~negative_customer_samples['CustomerId'].isin(positive_sample_customer_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "beeecb36-ae3e-4bbd-a52c-695e3c7e76d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_customer_samples['policy_activity_length'] = negative_customer_samples['maxPolicyExpirationDate'] - negative_customer_samples['minPolicyEffectiveDate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9ac27c4d-6b09-42f4-bd47-91396cd9ca71",
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_customer_samples['policy_activity_length'] = negative_customer_samples['policy_activity_length'].dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "72fc33a8-267c-4088-902e-09f4c1174668",
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_customer_samples = negative_customer_samples.loc[negative_customer_samples['policy_activity_length'] > 365 * 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5a8eb2c6-7b35-4e4b-aede-e164e4c6e682",
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_customer_samples = negative_customer_samples.loc[negative_customer_samples['minPolicyEffectiveDate'] < '2022-01-01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aa0567b5-fb0d-4bbc-8695-1e1d4c58b881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hit a snag.\n",
      "Hit a snag.\n",
      "Hit a snag.\n",
      "Finished 100 additional iterations.\n",
      "Hit a snag.\n",
      "Hit a snag.\n",
      "Hit a snag.\n",
      "Finished 100 additional iterations.\n",
      "Finished 100 additional iterations.\n",
      "Hit a snag.\n",
      "Finished 100 additional iterations.\n",
      "Hit a snag.\n",
      "Hit a snag.\n",
      "Finished 100 additional iterations.\n",
      "Finished 100 additional iterations.\n",
      "Finished 100 additional iterations.\n",
      "Hit a snag.\n",
      "Finished 100 additional iterations.\n",
      "Finished 100 additional iterations.\n",
      "Hit a snag.\n",
      "Finished 100 additional iterations.\n",
      "Hit a snag.\n",
      "Hit a snag.\n",
      "Finished 100 additional iterations.\n",
      "Hit a snag.\n",
      "Finished 100 additional iterations.\n",
      "Finished 100 additional iterations.\n",
      "Finished 100 additional iterations.\n",
      "Hit a snag.\n",
      "Finished 100 additional iterations.\n",
      "Hit a snag.\n",
      "Finished 100 additional iterations.\n",
      "Hit a snag.\n",
      "Finished 100 additional iterations.\n",
      "Hit a snag.\n",
      "Hit a snag.\n",
      "Finished 100 additional iterations.\n",
      "Finished 100 additional iterations.\n",
      "Finished 100 additional iterations.\n",
      "Hit a snag.\n",
      "Finished 100 additional iterations.\n",
      "Hit a snag.\n"
     ]
    }
   ],
   "source": [
    "all_negative_customer_data = pd.DataFrame([], columns = [\n",
    "    'min_policy_date', 'sum_policy_premiums',\n",
    "    'sum_location_premiums', 'no_previous_equipment',\n",
    "    'state', 'sum_of_deductibles',\n",
    "    'avg_equipment_year', 'total_claim_amount', 'churned'\n",
    "])\n",
    "\n",
    "for _, negative_customer_row in negative_customer_samples.iterrows():\n",
    "    random_dates_for_customer = pd.to_datetime( \\\n",
    "        random.choices(pd.date_range(negative_customer_row['minPolicyEffectiveDate'], '2022-01-01') \\\n",
    "        .tolist(), k = 10)).values.astype(str)\n",
    "    \n",
    "    customer_ids = np.zeros(10) + negative_customer_row['CustomerId']\n",
    "    \n",
    "    customer_probe_data = np.vstack((customer_ids.astype(str), random_dates_for_customer)).T\n",
    "\n",
    "    customer_probe_dates = pd.DataFrame(customer_probe_data, columns = ['CustomerId', 'ProbeDate'])\n",
    "\n",
    "    customer_probe_dates['CustomerId'] = customer_probe_dates['CustomerId'].astype(float).astype(int)\n",
    "    customer_probe_dates['ProbeDate'] = pd.to_datetime(customer_probe_dates['ProbeDate']).dt.date.astype(str)\n",
    "    \n",
    "    def first(x):\n",
    "        return x.iloc[0]\n",
    "    \n",
    "    def row_count(x):\n",
    "        return len(x)\n",
    "    \n",
    "    all_probe_data = []\n",
    "\n",
    "    try:\n",
    "        for index, row in customer_probe_dates.iterrows():\n",
    "            filtered_premium_df = premiums_df.loc[(premiums_df['CustomerId'] == negative_customer_row['CustomerId']) & (premiums_df['PolicyEffectiveDate'] < str(row['ProbeDate']))]\n",
    "            \n",
    "            probe_premium_data = filtered_premium_df.agg({\n",
    "                'PolicyEffectiveDate': 'min',\n",
    "                'PolicyPremium': 'sum',\n",
    "                'LocationPremium': 'sum',\n",
    "                'Loc': 'max',\n",
    "                'State': first,\n",
    "                'Deductible': 'sum',\n",
    "                'Equip Year': 'mean'\n",
    "            }).values\n",
    "        \n",
    "            filtered_claims_df = claims_df.loc[(claims_df['CustomerId'] == customer_id) & (claims_df['PolicyEffectiveDate'] < row['ProbeDate'])]\n",
    "            probe_claims_data = filtered_claims_df.agg({\n",
    "                'TotalPaidToDate': 'sum'\n",
    "            }).values\n",
    "        \n",
    "            probe_data = list(probe_premium_data.astype(str)) + list(probe_claims_data.astype(str)) + ['0']\n",
    "        \n",
    "            all_probe_data.append(probe_data)\n",
    "        \n",
    "        customer_data = pd.DataFrame(all_probe_data, columns = [\n",
    "            'min_policy_date', 'sum_policy_premiums',\n",
    "            'sum_location_premiums', 'no_previous_equipment',\n",
    "            'state', 'sum_of_deductibles',\n",
    "            'avg_equipment_year', 'total_claim_amount', 'churned'\n",
    "        ])\n",
    "        \n",
    "        customer_data = customer_data.drop_duplicates()\n",
    "        \n",
    "        all_negative_customer_data = pd.concat([all_negative_customer_data, customer_data], ignore_index = True)\n",
    "        \n",
    "        iteration += 1\n",
    "        if iteration % 100 == 0:\n",
    "            print('Finished 100 additional iterations.')\n",
    "    except Exception as e:\n",
    "        print('Hit a snag.')\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c53aa310-544a-45d8-9300-a1ce42d4c850",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>min_policy_date</th>\n",
       "      <th>sum_policy_premiums</th>\n",
       "      <th>sum_location_premiums</th>\n",
       "      <th>no_previous_equipment</th>\n",
       "      <th>state</th>\n",
       "      <th>sum_of_deductibles</th>\n",
       "      <th>avg_equipment_year</th>\n",
       "      <th>total_claim_amount</th>\n",
       "      <th>churned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-03-11 00:00:00</td>\n",
       "      <td>5280</td>\n",
       "      <td>2474.125662376987</td>\n",
       "      <td>1</td>\n",
       "      <td>NE</td>\n",
       "      <td>4000</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-03-11 00:00:00</td>\n",
       "      <td>7920</td>\n",
       "      <td>3711.1884935654807</td>\n",
       "      <td>1</td>\n",
       "      <td>NE</td>\n",
       "      <td>6000</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-03-11 00:00:00</td>\n",
       "      <td>2640</td>\n",
       "      <td>1237.0628311884934</td>\n",
       "      <td>1</td>\n",
       "      <td>NE</td>\n",
       "      <td>2000</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-03-11 00:00:00</td>\n",
       "      <td>11188</td>\n",
       "      <td>5242.648110067514</td>\n",
       "      <td>1</td>\n",
       "      <td>NE</td>\n",
       "      <td>8000</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-07-30 00:00:00</td>\n",
       "      <td>1480</td>\n",
       "      <td>1480.0</td>\n",
       "      <td>1</td>\n",
       "      <td>KS</td>\n",
       "      <td>1000</td>\n",
       "      <td>1979.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       min_policy_date sum_policy_premiums sum_location_premiums  \\\n",
       "0  2018-03-11 00:00:00                5280     2474.125662376987   \n",
       "1  2018-03-11 00:00:00                7920    3711.1884935654807   \n",
       "2  2018-03-11 00:00:00                2640    1237.0628311884934   \n",
       "3  2018-03-11 00:00:00               11188     5242.648110067514   \n",
       "4  2020-07-30 00:00:00                1480                1480.0   \n",
       "\n",
       "  no_previous_equipment state sum_of_deductibles avg_equipment_year  \\\n",
       "0                     1    NE               4000             2002.0   \n",
       "1                     1    NE               6000             2002.0   \n",
       "2                     1    NE               2000             2002.0   \n",
       "3                     1    NE               8000             2002.0   \n",
       "4                     1    KS               1000             1979.0   \n",
       "\n",
       "  total_claim_amount churned  \n",
       "0                0.0       0  \n",
       "1                0.0       0  \n",
       "2                0.0       0  \n",
       "3                0.0       0  \n",
       "4                0.0       0  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_negative_customer_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "61bfb58a-1c48-4b86-94dc-3375dc996bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_negative_customer_data.to_csv('../data/churn_modeling/churn_prediction_negative_samples.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
